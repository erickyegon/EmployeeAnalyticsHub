{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets connect to the database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Manual parsing of .env file\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.env\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# Manual parsing of .env file\n",
    "with open('.env') as f:\n",
    "    for line in f:\n",
    "        if line.strip() and not line.startswith('#'):\n",
    "            key, value = line.strip().split('=', 1)\n",
    "            os.environ[key] = value\n",
    "\n",
    "# Access the environment variables\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "\n",
    "# Print connection details (with masked password)\n",
    "print(f\"Connecting to MySQL at {db_host}:{db_port}\")\n",
    "print(f\"Database: {db_name}\")\n",
    "print(f\"User: {db_user}\")\n",
    "print(f\"Password: {'*' * len(db_password) if db_password else 'None'}\")\n",
    "\n",
    "# Import SQLAlchemy after installing it\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create MySQL connection string\n",
    "connection_string = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "try:\n",
    "    # Try to create the engine\n",
    "    print(\"Creating SQLAlchemy engine...\")\n",
    "    engine = create_engine(connection_string, echo=False)\n",
    "    \n",
    "    # Try to connect\n",
    "    print(\"Attempting to connect...\")\n",
    "    connection = engine.connect()\n",
    "    print(\"Connection successful!\")\n",
    "    connection.close()\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"Driver error: {e}\")\n",
    "    print(\"Please install the required database driver:\")\n",
    "    print(\"pip install pymysql\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the database: {e}\")\n",
    "    print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Demographics & Diversity (Basic & Aggregation Queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the total number of employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mSELECT COUNT(*) AS total_employees\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mFROM employees;\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m total_employees \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query, engine)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\"\"SELECT COUNT(*) AS total_employees\n",
    "FROM employees;\n",
    "\"\"\"\n",
    "\n",
    "total_employees = pd.read_sql(query, engine)\n",
    "print(total_employees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the gender distribution of employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    gender,\n",
    "    COUNT(*) AS employee_count,\n",
    "    COUNT(*) * 1.0 / (SELECT COUNT(*) FROM employees) AS gender_ratio\n",
    "FROM employees\n",
    "GROUP BY gender;\"\"\"\n",
    "gender_distribution = pd.read_sql(query,engine)\n",
    "\n",
    "gender_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic grouping with a subquery for proportional analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the race/ethnicity distribution across different departments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    department,\n",
    "    race,\n",
    "    COUNT(*) AS race_count,\n",
    "    COUNT(*) * 1.0 / SUM(COUNT(*)) OVER (PARTITION BY department) AS race_ratio\n",
    "FROM employees\n",
    "GROUP BY department, race\n",
    "ORDER BY department, race_count DESC;\"\"\"\n",
    "\n",
    "race_distribution = pd.read_sql(query,engine)\n",
    "race_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses window functions for departmental race proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the age distribution of employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"SELECT \n",
    "    FLOOR(DATEDIFF(YEAR, birthdate, '2025-03-12') / 10) * 10 AS age_range_start,\n",
    "    COUNT(*) AS employee_count\n",
    "FROM employees\n",
    "GROUP BY FLOOR(DATEDIFF(YEAR, birthdate, '2025-03-12') / 10) * 10\n",
    "ORDER BY age_range_start;\"\"\"\n",
    "\n",
    "age_distribution =pd.read_sql(query,engine)\n",
    "age_distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groups ages into decades using date functions and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the average age of employees in each department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"SELECT \n",
    "    department,\n",
    "    AVG(DATEDIFF(YEAR, birthdate, '2025-03-12')) AS avg_age,\n",
    "    MIN(DATEDIFF(YEAR, birthdate, '2025-03-12')) AS min_age,\n",
    "    MAX(DATEDIFF(YEAR, birthdate, '2025-03-12')) AS max_age\n",
    "FROM employees\n",
    "GROUP BY department\n",
    "ORDER BY avg_age DESC;\"\"\"\n",
    "avg_age_department= pd.read_sql(query,engine)\n",
    "avg_age_department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines multiple aggregations for a comprehensive departmental view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tenure & Employee Retention (Date Functions & Aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the average tenure of employees in each department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    department,\n",
    "    AVG(DATEDIFF(YEAR, hire_date, COALESCE(termdate, '2025-03-12'))) AS avg_tenure_years\n",
    "FROM employees\n",
    "GROUP BY department\n",
    "ORDER BY avg_tenure_years DESC;\"\"\"\n",
    "avg_tenure_dept = pd.read_sql(query,engine)\n",
    "avg_tenure_dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses COALESCE to handle active employees and date differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who are the top 5 longest-serving employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT TOP 5\n",
    "    id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    hire_date,\n",
    "    DATEDIFF(YEAR, hire_date, COALESCE(termdate, '2025-03-12')) AS tenure_years\n",
    "FROM employees\n",
    "ORDER BY tenure_years DESC;\"\"\"\n",
    "top_5_longtest_serving = pd.read_sql(query,engine)\n",
    "\n",
    "top_5_longtest_serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple ranking with TOP for seniority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What percentage of employees have left the company, and what is the average tenure of terminated employees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    COUNT(CASE WHEN termdate IS NOT NULL THEN 1 END) * 1.0 / COUNT(*) AS termination_rate,\n",
    "    AVG(CASE WHEN termdate IS NOT NULL THEN DATEDIFF(YEAR, hire_date, termdate) END) AS avg_tenure_terminated\n",
    "FROM employees;\"\"\"\n",
    "term_rate  = pd.read_sql(query,engine)\n",
    "term_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional aggregation for turnover metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the attrition rate for each department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    department,\n",
    "    COUNT(CASE WHEN termdate IS NOT NULL THEN 1 END) AS terminations,\n",
    "    COUNT(*) AS total_employees,\n",
    "    COUNT(CASE WHEN termdate IS NOT NULL THEN 1 END) * 1.0 / COUNT(*) AS attrition_rate\n",
    "FROM employees\n",
    "GROUP BY department\n",
    "ORDER BY attrition_rate DESC;\"\"\"\n",
    "attrition_rate_perdept = pd.read_sql(query,engine)\n",
    "attrition_rate_perdept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many employees were hired in each year, and what is the hiring trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Departmental turnover analysis with ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    YEAR(hire_date) AS hire_year,\n",
    "    COUNT(*) AS hires,\n",
    "    SUM(COUNT(*)) OVER (ORDER BY YEAR(hire_date)) AS cumulative_hires\n",
    "FROM employees\n",
    "GROUP BY YEAR(hire_date)\n",
    "ORDER BY hire_year;\"\"\"\n",
    "hiring_trends=pd.read_sql(query,engine)\n",
    "hiring_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracks hiring trends with a cumulative sum using window functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Queries (CTEs, Window Functions, Rank, Performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank employees by tenure within each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    department,\n",
    "    DATEDIFF(YEAR, hire_date, COALESCE(termdate, '2025-03-12')) AS tenure_years,\n",
    "    RANK() OVER (PARTITION BY department ORDER BY DATEDIFF(YEAR, hire_date, COALESCE(termdate, '2025-03-12')) DESC) AS tenure_rank\n",
    "FROM employees\n",
    "ORDER BY department, tenure_rank;\"\"\"\n",
    "tenure_rank = pd.read_sql(query,engine)\n",
    "tenure_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses RANK() for intra-departmental seniority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify employees who were hired and left within 2 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    hire_date,\n",
    "    termdate,\n",
    "    DATEDIFF(YEAR, hire_date, termdate) AS tenure_years\n",
    "FROM employees\n",
    "WHERE termdate IS NOT NULL \n",
    "AND DATEDIFF(YEAR, hire_date, termdate) <= 2\n",
    "ORDER BY hire_date;\"\"\"\n",
    "\n",
    "left_within2_years = pd.read_sql(query,engine)\n",
    "left_within2_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters short-tenure terminations with date logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the rolling 12-month average of employee terminations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"WITH Terminations AS (\n",
    "    SELECT \n",
    "        DATEADD(MONTH, DATEDIFF(MONTH, 0, termdate), 0) AS term_month,\n",
    "        COUNT(*) AS term_count\n",
    "    FROM employees\n",
    "    WHERE termdate IS NOT NULL\n",
    "    GROUP BY DATEADD(MONTH, DATEDIFF(MONTH, 0, termdate), 0)\n",
    ")\n",
    "SELECT \n",
    "    term_month,\n",
    "    term_count,\n",
    "    AVG(term_count * 1.0) OVER (ORDER BY term_month ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS rolling_12month_avg\n",
    "FROM Terminations\n",
    "ORDER BY term_month;\"\"\"\n",
    "avg_12month_terminations= pd.read_sql(query,engine)\n",
    "avg_12month_terminations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses a rolling window with date truncation for trend analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find employees whose hire date is within 30 days of their birth month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT \n",
    "    id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    birthdate,\n",
    "    hire_date,\n",
    "    DATEDIFF(DAY, DATEADD(YEAR, DATEDIFF(YEAR, birthdate, hire_date), birthdate), hire_date) AS days_from_birthday\n",
    "FROM employees\n",
    "WHERE ABS(DATEDIFF(DAY, DATEADD(YEAR, DATEDIFF(YEAR, birthdate, hire_date), birthdate), hire_date)) <= 30;\"\"\"\n",
    "hire_date_birth_month = pd.read_sql(query,engine)\n",
    "hire_date_birth_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex date comparison to align hire dates with birthdays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect anomalies in termdates (e.g., employees who left before their hire date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"\"\"SELECT \n",
    "    id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    hire_date,\n",
    "    termdate\n",
    "FROM employees\n",
    "WHERE termdate IS NOT NULL \n",
    "AND termdate < hire_date;\"\"\"\n",
    "\n",
    "termdate_anomalies= pd.read_sql(query,engine)\n",
    "termdate_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifies data quality issues with logical date checks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Optimization (Indexes, Partitions, Views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an indexed view that shows active employees by department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create the view (execute as a separate statement)\n",
    "create_view_query = \"\"\"CREATE VIEW vw_ActiveEmployeesByDept\n",
    "WITH SCHEMABINDING\n",
    "AS\n",
    "    SELECT \n",
    "        department,\n",
    "        COUNT_BIG(*) AS active_employee_count\n",
    "    FROM dbo.employees\n",
    "    WHERE termdate IS NULL\n",
    "    GROUP BY department;\"\"\"\n",
    "\n",
    "# Execute the CREATE VIEW statement\n",
    "engine.execute(create_view_query)\n",
    "\n",
    "# Second, create the index (as a separate statement)\n",
    "create_index_query = \"\"\"CREATE UNIQUE CLUSTERED INDEX IDX_vw_ActiveEmployeesByDept \n",
    "                        ON vw_ActiveEmployeesByDept(department);\"\"\"\n",
    "\n",
    "# Execute the CREATE INDEX statement\n",
    "engine.execute(create_index_query)\n",
    "\n",
    "# Now query the view to get the data\n",
    "query = \"SELECT * FROM vw_ActiveEmployeesByDept;\"\n",
    "active_employees_by_dept = pd.read_sql(query, engine)\n",
    "active_employees_by_dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizes queries for active employees with an indexed view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize a query to find employees hired before 2010 with indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create the nonclustered index\n",
    "create_index_query = \"\"\"CREATE NONCLUSTERED INDEX IDX_Employees_HireDate \n",
    "                        ON employees(hire_date);\"\"\"\n",
    "\n",
    "# Execute the CREATE INDEX statement\n",
    "engine.execute(create_index_query)\n",
    "\n",
    "# Then, query the data using the index\n",
    "query = \"\"\"SELECT \n",
    "    id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    hire_date\n",
    "FROM employees\n",
    "WHERE hire_date < '2010-01-01'\n",
    "ORDER BY hire_date;\"\"\"\n",
    "\n",
    "# Store the result in a DataFrame\n",
    "early_hires = pd.read_sql(query, engine)\n",
    "\n",
    "# Display the DataFrame\n",
    "early_hires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improves performance with a non-clustered index on `hire_date`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use partitioning to speed up queries for employees by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the partition function\n",
    "partition_function_query = \"\"\"CREATE PARTITION FUNCTION pf_LocationState (NVARCHAR(50))\n",
    "AS RANGE LEFT FOR VALUES ('Ohio', 'Texas');\"\"\"\n",
    "engine.execute(partition_function_query)\n",
    "\n",
    "# Step 2: Create the partition scheme\n",
    "partition_scheme_query = \"\"\"CREATE PARTITION SCHEME ps_LocationState\n",
    "AS PARTITION pf_LocationState ALL TO ([PRIMARY]);\"\"\"\n",
    "engine.execute(partition_scheme_query)\n",
    "\n",
    "# Step 3: Create the partitioned table\n",
    "create_table_query = \"\"\"CREATE TABLE employees_partitioned (\n",
    "    id NVARCHAR(10), first_name NVARCHAR(50), last_name NVARCHAR(50), birthdate DATE, \n",
    "    gender NVARCHAR(10), race NVARCHAR(50), department NVARCHAR(50), jobtitle NVARCHAR(50), \n",
    "    location NVARCHAR(50), hire_date DATE, termdate DATE, location_city NVARCHAR(50), \n",
    "    location_state NVARCHAR(50)\n",
    ") ON ps_LocationState(location_state);\"\"\"\n",
    "engine.execute(create_table_query)\n",
    "\n",
    "# Step 4: Insert data from the original table\n",
    "insert_data_query = \"\"\"INSERT INTO employees_partitioned SELECT * FROM employees;\"\"\"\n",
    "engine.execute(insert_data_query)\n",
    "\n",
    "# Step 5: Query data from the partitioned table\n",
    "query = \"\"\"SELECT * FROM employees_partitioned WHERE location_state = 'Ohio';\"\"\"\n",
    "ohio_employees = pd.read_sql(query, engine)\n",
    "\n",
    "# Display the results\n",
    "ohio_employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitions data by state for faster location-based queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a stored procedure to get employee counts by department for a given date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the stored procedure\n",
    "create_procedure_query = \"\"\"CREATE PROCEDURE sp_EmployeeCountByDept\n",
    "    @StartDate DATE,\n",
    "    @EndDate DATE\n",
    "AS\n",
    "BEGIN\n",
    "    SELECT \n",
    "        department,\n",
    "        COUNT(*) AS employee_count\n",
    "    FROM employees\n",
    "    WHERE hire_date <= @EndDate \n",
    "    AND (termdate IS NULL OR termdate >= @StartDate)\n",
    "    GROUP BY department\n",
    "    ORDER BY employee_count DESC;\n",
    "END;\"\"\"\n",
    "\n",
    "# Execute the CREATE PROCEDURE statement\n",
    "engine.execute(create_procedure_query)\n",
    "\n",
    "# Step 2: Execute the stored procedure with parameters\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    'StartDate': '2020-01-01', \n",
    "    'EndDate': '2025-03-12'\n",
    "}\n",
    "\n",
    "# Call the stored procedure\n",
    "exec_query = text(\"EXEC sp_EmployeeCountByDept @StartDate = :StartDate, @EndDate = :EndDate;\")\n",
    "dept_counts = pd.read_sql(exec_query, engine, params=params)\n",
    "\n",
    "# Display the results\n",
    "dept_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulates logic for reusable, parameterized reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a materialized view for high-speed analytics on employee demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the view with SCHEMABINDING\n",
    "create_view_query = \"\"\"CREATE VIEW vw_EmployeeDemographics\n",
    "WITH SCHEMABINDING\n",
    "AS\n",
    "    SELECT \n",
    "        department,\n",
    "        gender,\n",
    "        race,\n",
    "        AVG(DATEDIFF(YEAR, birthdate, '2025-03-12')) AS avg_age,\n",
    "        COUNT_BIG(*) AS employee_count\n",
    "    FROM dbo.employees\n",
    "    GROUP BY department, gender, race;\"\"\"\n",
    "\n",
    "# Execute the CREATE VIEW statement\n",
    "engine.execute(create_view_query)\n",
    "\n",
    "# Step 2: Create the unique clustered index on the view\n",
    "# Note: Remove the GO statement as it's not needed for Python execution\n",
    "create_index_query = \"\"\"CREATE UNIQUE CLUSTERED INDEX IDX_vw_EmployeeDemographics \n",
    "                        ON vw_EmployeeDemographics(department, gender, race);\"\"\"\n",
    "\n",
    "# Execute the CREATE INDEX statement\n",
    "engine.execute(create_index_query)\n",
    "\n",
    "# Optional Step 3: Query the view to see the results\n",
    "query = \"SELECT * FROM vw_EmployeeDemographics ORDER BY department, gender, race;\"\n",
    "employee_demographics = pd.read_sql(query, engine)\n",
    "\n",
    "# Display the results\n",
    "employee_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-aggregates demographics for rapid analytics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
